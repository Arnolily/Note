
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../Feature%20learning%20from%20Continual%20Learning/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.21">
    
    
      
        <title>My comprehension of Resnet and Batch Norms - Arnolily</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.66ac8b77.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#my-comprehension-of-resnet-and-batch-norms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Arnolily" class="md-header__button md-logo" aria-label="Arnolily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Arnolily
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              My comprehension of Resnet and Batch Norms
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Arnolily" class="md-nav__button md-logo" aria-label="Arnolily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Arnolily
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    My Daily Life and Thoughts on Science
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../FF%26Hinton/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Forward-Forward Algorithm: A New Revolution Brought by Geoffrey Hinton
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Feature%20learning%20from%20Continual%20Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Feature learning from Continual Learning
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    My comprehension of Resnet and Batch Norms
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    My comprehension of Resnet and Batch Norms
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#my-understanding-of-skip-connections-and-batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      My Understanding of Skip-Connections and Batch Normalization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-batch-normalization-bn" class="md-nav__link">
    <span class="md-ellipsis">
      Possible Advantages of Batch Normalization (BN)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible Advantages of Batch Normalization (BN)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#improving-numerical-stability" class="md-nav__link">
    <span class="md-ellipsis">
      Improving Numerical Stability
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perhaps-not-alleviating-internal-covariate-shift-1" class="md-nav__link">
    <span class="md-ellipsis">
      (Perhaps Not) Alleviating Internal Covariate Shift [1]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smoother-loss-landscape-2" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother Loss Landscape [2]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#better-use-of-non-linearity-3" class="md-nav__link">
    <span class="md-ellipsis">
      Better Use of Non-linearity [3]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-skip-connections" class="md-nav__link">
    <span class="md-ellipsis">
      Possible Advantages of Skip-Connections
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible Advantages of Skip-Connections">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#smoother-gradient-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother Gradient Flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solving-the-network-degradation-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Solving the Network Degradation Problem
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#my-understanding-of-skip-connections-and-batch-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      My Understanding of Skip-Connections and Batch Normalization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-batch-normalization-bn" class="md-nav__link">
    <span class="md-ellipsis">
      Possible Advantages of Batch Normalization (BN)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible Advantages of Batch Normalization (BN)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#improving-numerical-stability" class="md-nav__link">
    <span class="md-ellipsis">
      Improving Numerical Stability
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perhaps-not-alleviating-internal-covariate-shift-1" class="md-nav__link">
    <span class="md-ellipsis">
      (Perhaps Not) Alleviating Internal Covariate Shift [1]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smoother-loss-landscape-2" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother Loss Landscape [2]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#better-use-of-non-linearity-3" class="md-nav__link">
    <span class="md-ellipsis">
      Better Use of Non-linearity [3]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-skip-connections" class="md-nav__link">
    <span class="md-ellipsis">
      Possible Advantages of Skip-Connections
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible Advantages of Skip-Connections">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#smoother-gradient-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother Gradient Flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solving-the-network-degradation-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Solving the Network Degradation Problem
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="my-comprehension-of-resnet-and-batch-norms">My comprehension of Resnet and Batch Norms</h1>
<blockquote>
<p>Skip-connections and rescaling (including normalization) appear in most neural networks. However, some papers use these techniques inappropriately, causing unnecessary network complexity. It is therefore important to revisit the basics for both experimental inspiration and theoretical understanding.</p>
</blockquote>
<h2 id="my-understanding-of-skip-connections-and-batch-normalization"><strong>My Understanding of Skip-Connections and Batch Normalization</strong></h2>
<p><em>Skip-connections and rescaling (including normalization) appear in most neural networks. However, some papers use these techniques inappropriately, causing unnecessary network complexity. It is therefore important to revisit the basics for both experimental inspiration and theoretical understanding.</em></p>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>1ae913e099db580890c8e6fa923121c61b1edfb7</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<h2 id="possible-advantages-of-batch-normalization-bn"><strong>Possible Advantages of Batch Normalization (BN)</strong></h2>
<h3 id="improving-numerical-stability"><strong>Improving Numerical Stability</strong></h3>
<p>Suppose we have a 1-layer linear neural network for a regression problem. The output <script type="math/tex">o</script> and the Mean Squared Error (MSE) loss <script type="math/tex">\mathcal{L}_{MSE}</script> are:</p>
<p>
<script type="math/tex; mode=display">o = \sigma(w \cdot x)</script>
<br />
<script type="math/tex; mode=display">\mathcal{L}_{MSE} = \frac{1}{2}(o - y)^2</script>
</p>
<p>Through backpropagation, the gradient <script type="math/tex">\nabla \mathcal{L}_{w}</script> is:</p>
<p>
<script type="math/tex; mode=display">\nabla \mathcal{L}_{w} = (o - y) \cdot \frac{\partial o}{\partial (w)} = o \cdot x \cdot \sigma'</script>
</p>
<p>If the network has <script type="math/tex">N</script> layers, then the gradient of the first layer would be <script type="math/tex">o \cdot \prod_{i=1}^{N} \frac{\partial o}{\partial (w)}</script>, and the product of this sequence would tend to 0 or infinity. This is <strong>numerical instability</strong>.</p>
<p>With BN, we can restrict <script type="math/tex">x</script> to any Gaussian distribution, thus mitigating the instability of <script type="math/tex">x</script> and <script type="math/tex">\sigma'</script>.</p>
<h3 id="perhaps-not-alleviating-internal-covariate-shift-1"><strong>(Perhaps Not) Alleviating Internal Covariate Shift</strong> [1]</h3>
<p>In the original paper on Batch Normalization, they defined Internal Covariate Shift (ICS).</p>
<blockquote>
<p>ICS is the phenomenon where the distribution of inputs to a layer in the network changes due to an update of parameters in previous layers.</p>
</blockquote>
<p>Mathematically, each layer can be derived as:</p>
<p>
<script type="math/tex; mode=display">Y = \mathcal{F}\{X\}</script>
</p>
<p>where <script type="math/tex">\mathcal{F}</script> is the mapping function between input <script type="math/tex">X</script> and output <script type="math/tex">Y</script>. Essentially, layers are learning this map between input patterns and output patterns. However, due to ICS, the input pattern could constantly change, which might disrupt the learned mapping function. Therefore, ICS is believed to have a detrimental effect on the training process.</p>
<p>However, I propose an alternative understanding of ICS. In traditional machine learning, we assume that data are <strong>IID</strong> (i.e., independently and identically distributed). This is the foundation of machine learning and the prerequisite of <strong>MLE</strong> (i.e., Maximum Likelihood Estimation), which is the original form of all loss functions. By using BN, we can ensure the second <strong>I</strong> in <strong>IID</strong>, which is identically distributed. This could lead to better generalization performance for the network.</p>
<p><em>Other researchers, however, have shown that ICS does not affect performance and that BN does not reduce ICS.</em> They prefer to explain BN’s effectiveness differently.</p>
<h3 id="smoother-loss-landscape-2"><strong>Smoother Loss Landscape</strong> [2]</h3>
<p>These researchers demonstrated that BN contributes to a smoother loss landscape, which can be visualized:</p>
<p><img alt="Loss Landscape" src="../Landscape.png" /></p>
<p>With BN, the loss landscape is smoother, which improves training efficiency and allows for a higher learning rate.</p>
<h3 id="better-use-of-non-linearity-3"><strong>Better Use of Non-linearity</strong> [3]</h3>
<p>Note that there is a linear transformation (i.e., scaling and shifting) applied after the feature map <script type="math/tex">x</script> is normalized.</p>
<p><img alt="Batch Normalization" src="../BN.png" style="height:300px;" /></p>
<p>Suppose we use the sigmoid function as the activation function.</p>
<p><img alt="Sigmoid Function" src="../sigmoid-function.png" style="height:300px;" /></p>
<p>It’s clear that for <script type="math/tex">x \in (-1, 1)</script>, we have <script type="math/tex">\sigma(x) \approx x</script>. This means the activation function acts almost as an identity transformation, which is not ideal because the purpose of an activation function is to add non-linearity to the model. Therefore, without scaling and shifting, the non-linearity would be weak, making the fitting process difficult.</p>
<p>Even for ReLU, which seems less affected, there are cases where all neurons are either activated <script type="math/tex">x > 0</script> or deactivated <script type="math/tex">x < 0</script>. If a ReLU neuron is always active, then it is linear; if it’s always inactive, it doesn’t contribute to the network.</p>
<p>From my perspective, however, this might not be BN’s most important contribution. Experiments have shown that placing BN after the activation function can sometimes improve network performance!</p>
<h2 id="possible-advantages-of-skip-connections"><strong>Possible Advantages of Skip-Connections</strong></h2>
<h3 id="smoother-gradient-flow"><strong>Smoother Gradient Flow</strong></h3>
<p>As pointed out in [4], authored by the ResNet creator He, one benefit of skip-connections is smoother gradient flow. For each skip layer, the output can be derived as:</p>
<p>
<script type="math/tex; mode=display">\mathbf{x}_{l+1} = \mathbf{x}_l + \mathcal{F}(\mathbf{x}_l, \mathcal{W}_l)</script>
</p>
<p>And the gradient is:</p>
<p>
<script type="math/tex; mode=display">\frac{\partial \mathcal{E}}{\partial \mathbf{x}_l} = \frac{\partial \mathcal{E}}{\partial \mathbf{x}_L} \frac{\partial \mathbf{x}_L}{\partial \mathbf{x}_l} = \frac{\partial \mathcal{E}}{\partial \mathbf{x}_L} \left(1 + \frac{\partial}{\partial \mathbf{x}_l} \sum_{i=l}^{L-1} \mathcal{F}(\mathbf{x}_i, \mathcal{W}_i)\right)</script>
</p>
<p>With ResNet, the gradient will be a sum of “geometric equations,” preventing it from vanishing.</p>
<h3 id="solving-the-network-degradation-problem"><strong>Solving the Network Degradation Problem</strong></h3>
<p>In the original ResNet paper, He claimed that ResNet solved the "network degradation problem." The idea was that if a deeper model performs worse than a shallower one on the test set, it implies that the additional layers in the deeper model are less effective than a straightforward identity mapping. If those extra layers simply acted as identity mappings, the deeper model would match the performance of the shallower model.</p>
<p>With this insight, he designed skip-connections, which are essentially manually added identity mappings.</p>
<p>The real question is, what causes network degradation? Is the degradation problem truly due to a failure to achieve identity mapping? This is an area where researchers differ, and I will present some interesting studies on the topic.</p>
<p><strong>Gradient Correlation [2]</strong></p>
<p>Balduzzi et al. [2] proposed a new explanation for network degradation. They first suggested that ResNet alleviates the shattered gradient problem. The shattered gradient problem is defined as follows:</p>
<blockquote>
<p>Shattered gradients undermine the effectiveness of algorithms that assume gradients at nearby points are similar, such as momentum-based and accelerated methods.</p>
</blockquote>
<p>Under this assumption, they quantified the shattered gradient problem as the autocorrelation function (ACF). A higher ACF leads to higher performance and a reduced shattered gradient problem. They demonstrated, through both mathematical proofs and experiments, that skip connections enhance ACF. However, their proof relied on very strong assumptions and was not entirely convincing to me.</p>
<p><img alt="Autocorrelation Function (ACF)" src="../ACF.png" title="title" /></p>
<h2 id="citation"><strong>Citation</strong></h2>
<p>[1] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.<br />
[2] How Does Batch Normalization Help Optimization?<br />
[3] The Shattered Gradients Problem: If ResNets Are the Answer, Then What Is the Question?<br />
[4] Identity Mappings in Deep Residual Networks.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.a7c05c9e.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>