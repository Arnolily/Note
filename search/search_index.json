{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"My Daily Life and Thoughts on Science","text":"<p>Welcome to my blog! Here you can find links to all my diaries. The purpose of this blog is to document and share the interesting knowledge I acquired.</p> <ul> <li> <p>My comprehension of Resnet and Batch Norms</p> </li> <li> <p>The Forward-Forward Algorithm: A New Revolution Brought by Geoffrey Hinton</p> </li> </ul>"},{"location":"FF%26Hinton/","title":"The Forward-Forward Algorithm: A New Revolution Brought by Geoffrey Hinton","text":"<p>At the age of 74, Geoffrey Hinton introduced a new algorithm to replace the backpropagation method\u2014the very technique he popularized in 1986\u2014in an effort to bring deep learning closer to a biologically plausible interpretation. This blog is to show respect for him and discuss my understanding of this work as well as recent developments on this amazing algorithm.</p> <p>And lo, he declared, \u201cLet there be a new way,\u201d and thus the Forward-Forward algorithm was brought forth, that it might supplant the backpropagation he had once bestowed upon the minds of men in the year of 1986. And it was good. ------ Hinton's Epiphany: A New Era in Deep Learning (I made this up)</p> <p></p>"},{"location":"FF%26Hinton/#prerequisite-problems-with-the-forward-backward-method","title":"Prerequisite: Problems with the Forward-Backward Method","text":"<p>Nowadays, most networks utilize Backpropagation (BP) to optimize the network. This is very effective, but its inherent flaws limit the upper bound of its capability. This inspired Hinton and the community to pursue a new method.</p>"},{"location":"FF%26Hinton/#what-is-the-limitation","title":"What is the limitation?","text":"<ol> <li> <p>First, BP uses the chain rule to compute derivatives. This requires the forward computational graph to be precise, with no black-box process allowed.</p> </li> <li> <p>Second, the ideal way to train a network should be continuous. For example, a robot should learn the rules of the world as it observes, with each frame and movement being directly processed by its brain. This stream of events should flow uninterrupted. It would seem unnatural if the robot had to stop observing every time it received a new frame to perform the BP process.</p> </li> <li> <p>Last, and most importantly, BP is not a biologically plausible learning mechanism. In fact, it is highly unlikely that optimization signals are propagated backward through the brain. This suggests that the human brain does not learn using BP. From a practical standpoint, this aligns with common sense. Models like ChatGPT rely on Backpropagation Through Time (BPTT) to adjust their parameters, but this process is clearly unfeasible in the real world\u2014how could a biological system, or any real-world process, literally travel backward through time?</p> </li> <li> <p>Of course, there are many other disadvantages to BP, but understanding that BP is not perfect is enough to continue reading.</p> </li> </ol>"},{"location":"FF%26Hinton/#a-brief-introduction-to-the-forward-forward-algorithm","title":"A Brief Introduction to the Forward-Forward Algorithm","text":"<p>The training process of the Forward-Forward Algorithm can be broken down into two processes: positive learning and negative learning. These two processes are executed in an alternating fashion\u2014first positive learning, then negative learning, then positive again, and then negative... Goodness is defined as the mean square of the output of each layer.</p>"},{"location":"FF%26Hinton/#a-loss","title":"A. Loss","text":"<p>During positive learning, we aim to lift up the goodness(output of each layer). The loss is:  where  is the output of each layer, and  is a hyper-parameter.</p> <p>During negative learning, we aim to push down the goodness. The loss is: </p>"},{"location":"FF%26Hinton/#b-data","title":"B. Data","text":"<p>During positive learning, we input 'fact.' During negative learning, we input 'delusion.'</p> <p>By 'fact,' we mean the ground truth, while 'delusion' refers to something random or generated by some generative models.</p> <p>For example, in a simple MNIST dataset classification problem, labels will be mapped to the first 10 pixels on the image. 'Fact' could be the image with the correct label mapping, while 'delusion' would be the image with a random label mapping.</p> <p> </p> <p>Another example for unsupervised learning would be 'fact' as the original image and 'delusion' as a combination of two different images.</p> <p></p> <p>For RNNs and language models, during the positive training period, inputs will be real text data from the dataset. After the positive training period, the model will generate a piece of text data to serve as input for the negative training period.</p>"},{"location":"FF%26Hinton/#c-inference","title":"C. Inference","text":"<p>During the inference process, the network will concatenate all the goodnesses from each layer, and choose the prediction with the biggest goodness.</p>"},{"location":"FF%26Hinton/#d-biological-inspiration","title":"D. Biological Inspiration","text":"<p>One of the fascinating aspects of Biologically Inspired Intelligence is that when we design networks based on biological principles, these networks often display phenomena that can help us better understand brain mechanisms, and FF could be one of them. Hinton pointed out, the training process of FF could be similar to how a infant understand the world. When an infant is awake, they observe the real world, where everything they see is treated as \"ground truth\"\u2014it's simply what is. Then, when he is asleep, his brain would attempts to replay and make sense of what it has learned. That could be in the form of dreams. In this analogy, the awake phrase would be positive training process, where the brain (or network) absorbs and experiences the world; and the asleep phrase would be negative training process, where the brain refines its understanding by processing and adjusting based on the knowledge it has gathered. </p> <p>Indeed, this is a fascinating analogy, but ultimately, it is up to each individual to decide whether they will buy this story.</p>"},{"location":"FF%26Hinton/#e-limitations","title":"E. Limitations","text":"<p>The original paper practiced this method on MLP only, and when I implemented the supervised method on a CNN, it failed, as expected. The label information, treated as marginal data, was lost during the convolution process. Since the only distinction between positive training and negative learning lies in the mapped label information, losing this information would result in a complete failure of the training process. Therefore, to dive deeper into the potential of the FF algorithm, we need to look for better ways to generate negative data.</p>"},{"location":"FF%26Hinton/#some-latest-progress-on-ff-algorithm","title":"Some latest progress on FF algorithm","text":""},{"location":"FF%26Hinton/#a-training-convolutional-neural-networks-with-the-forward-forward-algorithm","title":"A. Training Convolutional Neural Networks with the Forward-Forward Algorithm","text":"<p>This paper proposed an intuitive method for generating negative samples. They defined different labels as 2-D strips matching the size of the image and mapped them onto the images. Unlike the original 1-D one-hot labels, these 2-D labels are not treated as marginal information, meaning they are retained during convolution. As a result, they can be captured by the CNN model, potentially leading to better performance than the vanilla Forward-Forward (FF) algorithm.</p> <p>However, the results from my experiments indicate that this method may not be as effective on more complex datasets such as CIFAR-10 and CIFAR-100. Please note that the paper does not provide code, and it is possible, although not likely, that my re-implementation on the CIFAR datasets contain errors.</p> <p></p>"},{"location":"FF%26Hinton/#bconvolutional-channel-wise-competitive-learning-for-the-forward-forward-algorithm","title":"B.Convolutional Channel-wise Competitive Learning for the Forward-Forward Algorithm","text":"<p>This paper re-implemented the FF algorithm, and it changed the way to use label information. Still remember that we want to lift up the output during positive training and push down during negative training? This time, they combined the positive training and negative training. When their model is trained, the output of each layer will be uniformly divide into [num_of_classes] parts, on the channel dimension. Then, the magnitude of the part that aligns with the label will be lifted up, and the other parts will be pushed down. It would be better elaborated in this pseudo code:</p> <pre><code>output = layer(input) # dimension = [C, H, W]\nchannel_size = output.shape[0] # channel_size = C\nchannel_part = torch.split(output, \nchannel_size // num_of_classes, dim = 1) # divide output along the channel dimension\n\nloss_pos = torch.exp(1 + theta - channel_part[label].pow(2).mean())\n\nloss_net = torch.exp(1 - theta + channel_part[others].pow(2).mean())\n</code></pre> <p>This is a very innovative training method to me, and intuitively speaking, it treated every method as a classifier. It could work well on cifar-10 dataset, with an accuracy of 79%.</p> <p></p>"},{"location":"FF%26Hinton/#c-self-contrastive-forward-forward-algorithm","title":"C. Self-Contrastive Forward-Forward Algorithm","text":"<p>I believe this figure could do serve as an introduction. This method involves simply inputting two images and maximizing goodness when two images are the same, and minimizing goodness when they are not the same.</p> <p>The paper is still in preprint version and no code is provided, and I failed to reimplement their method. So I will make no comment about this idea.</p>"},{"location":"FF%26Hinton/#references","title":"References","text":"<p>The Forward-Forward Algorithm: Some Preliminary Investigations</p> <p>Training Convolutional Neural Networks with the Forward-Forward Algorithm</p> <p>Convolutional Channel-wise Competitive Learning for the Forward-Forward Algorithm</p> <p>Self-Contrastive Forward-Forward Algorithm</p> <p>Geoffrey Hinton Unpacks The Forward-Forward Algorithm [Youtube Video at: URL]</p>"},{"location":"Resnet%20%26%20Batch%20Norms/","title":"My comprehension of Resnet and Batch Norms","text":"<p>Skip-connections and rescaling (including normalization) appear in most neural networks. However, some papers use these techniques inappropriately, causing unnecessary network complexity. It is therefore important to revisit the basics for both experimental inspiration and theoretical understanding.</p>"},{"location":"Resnet%20%26%20Batch%20Norms/#possible-advantages-of-batch-normalization-bn","title":"Possible Advantages of Batch Normalization (BN)","text":""},{"location":"Resnet%20%26%20Batch%20Norms/#improving-numerical-stability","title":"Improving Numerical Stability","text":"<p>Suppose we have a 1-layer linear neural network for a regression problem. The output  and the Mean Squared Error (MSE) loss  are:</p> <p> </p> <p>Through backpropagation, the gradient  is:</p> <p> </p> <p>If the network has  layers, then the gradient of the first layer would be , and the product of this sequence would tend to 0 or infinity. This is numerical instability.</p> <p>With BN, we can restrict  to any Gaussian distribution, thus mitigating the instability of  and .</p>"},{"location":"Resnet%20%26%20Batch%20Norms/#perhaps-not-alleviating-internal-covariate-shift-1","title":"(Perhaps Not) Alleviating Internal Covariate Shift [1]","text":"<p>In the original paper on Batch Normalization, they defined Internal Covariate Shift (ICS).</p> <p>ICS is the phenomenon where the distribution of inputs to a layer in the network changes due to an update of parameters in previous layers.</p> <p>Mathematically, each layer can be derived as:</p> <p> </p> <p>where  is the mapping function between input  and output . Essentially, layers are learning this map between input patterns and output patterns. However, due to ICS, the input pattern could constantly change, which might disrupt the learned mapping function. Therefore, ICS is believed to have a detrimental effect on the training process.</p> <p>However, I propose an alternative understanding of ICS. In traditional machine learning, we assume that data are IID (i.e., independently and identically distributed). This is the foundation of machine learning and the prerequisite of MLE (i.e., Maximum Likelihood Estimation), which is the original form of all loss functions. By using BN, we can ensure the second I in IID, which is identically distributed. This could lead to better generalization performance for the network.</p> <p>Other researchers, however, have shown that ICS does not affect performance and that BN does not reduce ICS. They prefer to explain BN\u2019s effectiveness differently.</p>"},{"location":"Resnet%20%26%20Batch%20Norms/#smoother-loss-landscape-2","title":"Smoother Loss Landscape [2]","text":"<p>These researchers demonstrated that BN contributes to a smoother loss landscape, which can be visualized:</p> <p></p> <p>With BN, the loss landscape is smoother, which improves training efficiency and allows for a higher learning rate.</p>"},{"location":"Resnet%20%26%20Batch%20Norms/#better-use-of-non-linearity-3","title":"Better Use of Non-linearity [3]","text":"<p>Note that there is a linear transformation (i.e., scaling and shifting) applied after the feature map  is normalized.</p> <p></p> <p>Suppose we use the sigmoid function as the activation function.</p> <p></p> <p>It\u2019s clear that for , we have . This means the activation function acts almost as an identity transformation, which is not ideal because the purpose of an activation function is to add non-linearity to the model. Therefore, without scaling and shifting, the non-linearity would be weak, making the fitting process difficult.</p> <p>Even for ReLU, which seems less affected, there are cases where all neurons are either activated  or deactivated . If a ReLU neuron is always active, then it is linear; if it\u2019s always inactive, it doesn\u2019t contribute to the network.</p> <p>From my perspective, however, this might not be BN\u2019s most important contribution. Experiments have shown that placing BN after the activation function can sometimes improve network performance!</p>"},{"location":"Resnet%20%26%20Batch%20Norms/#possible-advantages-of-skip-connections","title":"Possible Advantages of Skip-Connections","text":""},{"location":"Resnet%20%26%20Batch%20Norms/#smoother-gradient-flow","title":"Smoother Gradient Flow","text":"<p>As pointed out in [4], authored by the ResNet creator He, one benefit of skip-connections is smoother gradient flow. For each skip layer, the output can be derived as:</p> <p> </p> <p>And the gradient is:</p> <p> </p> <p>With ResNet, the gradient will be a sum of \u201cgeometric equations,\u201d preventing it from vanishing.</p>"},{"location":"Resnet%20%26%20Batch%20Norms/#solving-the-network-degradation-problem","title":"Solving the Network Degradation Problem","text":"<p>In the original ResNet paper, He claimed that ResNet solved the \"network degradation problem.\" The idea was that if a deeper model performs worse than a shallower one on the test set, it implies that the additional layers in the deeper model are less effective than a straightforward identity mapping. If those extra layers simply acted as identity mappings, the deeper model would match the performance of the shallower model.</p> <p>With this insight, he designed skip-connections, which are essentially manually added identity mappings.</p> <p>The real question is, what causes network degradation? Is the degradation problem truly due to a failure to achieve identity mapping? This is an area where researchers differ, and I will present some interesting studies on the topic.</p> <p>Gradient Correlation [2]</p> <p>Balduzzi et al. [2] proposed a new explanation for network degradation. They first suggested that ResNet alleviates the shattered gradient problem. The shattered gradient problem is defined as follows:</p> <p>Shattered gradients undermine the effectiveness of algorithms that assume gradients at nearby points are similar, such as momentum-based and accelerated methods.</p> <p>Under this assumption, they quantified the shattered gradient problem as the autocorrelation function (ACF). A higher ACF leads to higher performance and a reduced shattered gradient problem. They demonstrated, through both mathematical proofs and experiments, that skip connections enhance ACF. However, their proof relied on very strong assumptions and was not entirely convincing to me.</p> <p></p>"},{"location":"Resnet%20%26%20Batch%20Norms/#citation","title":"Citation","text":"<p>[1] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. [2] How Does Batch Normalization Help Optimization? [3] The Shattered Gradients Problem: If ResNets Are the Answer, Then What Is the Question? [4] Identity Mappings in Deep Residual Networks.</p>"}]}