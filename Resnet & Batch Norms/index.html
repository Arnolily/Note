
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.21">
    
    
      
        <title>My comprehension of Skip-connection and Batch Norms - Arnolily</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.66ac8b77.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#my-comprehension-of-skip-connection-and-batch-norms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Arnolily" class="md-header__button md-logo" aria-label="Arnolily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Arnolily
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              My comprehension of Skip-connection and Batch Norms
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Arnolily" class="md-nav__button md-logo" aria-label="Arnolily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Arnolily
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    My Daily Life and Thoughts on Science
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    My comprehension of Skip-connection and Batch Norms
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    My comprehension of Skip-connection and Batch Norms
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-bn" class="md-nav__link">
    <span class="md-ellipsis">
      Possible advantages of BN.
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible advantages of BN.">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#improving-numerical-stability" class="md-nav__link">
    <span class="md-ellipsis">
      Improving Numerical stability
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perhaps-not-alleviate-internal-covariate-shift-1" class="md-nav__link">
    <span class="md-ellipsis">
      (Perhaps not) Alleviate Internal Covariate Shift [1]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smoother-loss-landscape-2" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother Loss landscape [2]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#better-use-of-non-linearity-3" class="md-nav__link">
    <span class="md-ellipsis">
      Better use of non-linearity [3]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-skip-connection" class="md-nav__link">
    <span class="md-ellipsis">
      Possible advantages of Skip-connection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible advantages of Skip-connection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#smoother-gradient-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother gradient flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solving-network-degradation-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Solving network degradation problem
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-bn" class="md-nav__link">
    <span class="md-ellipsis">
      Possible advantages of BN.
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible advantages of BN.">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#improving-numerical-stability" class="md-nav__link">
    <span class="md-ellipsis">
      Improving Numerical stability
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perhaps-not-alleviate-internal-covariate-shift-1" class="md-nav__link">
    <span class="md-ellipsis">
      (Perhaps not) Alleviate Internal Covariate Shift [1]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#smoother-loss-landscape-2" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother Loss landscape [2]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#better-use-of-non-linearity-3" class="md-nav__link">
    <span class="md-ellipsis">
      Better use of non-linearity [3]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#possible-advantages-of-skip-connection" class="md-nav__link">
    <span class="md-ellipsis">
      Possible advantages of Skip-connection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Possible advantages of Skip-connection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#smoother-gradient-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Smoother gradient flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solving-network-degradation-problem" class="md-nav__link">
    <span class="md-ellipsis">
      Solving network degradation problem
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="my-comprehension-of-skip-connection-and-batch-norms"><strong>My comprehension of Skip-connection and Batch Norms</strong></h1>
<p><strong><em>Skip-connections and rescaling (including normalization) appears in most of the networks. However, some paper would choose to use these tricks inappropriately, causing unnecessary network complexity. It is therefore important to take a look back at the basics, for both experimental inspiration and theoretical understanding.</em></strong></p>
<h2 id="possible-advantages-of-bn"><strong>Possible advantages of BN.</strong></h2>
<h3 id="improving-numerical-stability"><strong>Improving Numerical stability</strong></h3>
<p>Suppose we have a 1-layer Linear Neural Network for regression problem, the output <script type="math/tex">o</script> and MSE loss <script type="math/tex">\mathcal{L}_{MSE}</script> is:
<script type="math/tex; mode=display">o=\sigma(w \cdot x)</script>
<script type="math/tex; mode=display">\mathcal{L}_{MSE}=\frac{1} {2}(o-y)^2</script>
Through back propagation, <script type="math/tex">\nabla \mathcal{L}_{w}=(o-y)\cdot \frac{\partial o} {\partial (w)}=o\cdot x\cdot \sigma'</script>
<br />
If the net has N layers, then the gradient of the first layer would be <script type="math/tex">o \cdot \prod_{i=1}^{N} \frac{\partial o} {\partial (w)}</script>, and the product of this sequence would tend to 0 or <em>inf</em>. This is <strong>Numerical instability</strong>.</p>
<p>With BN, we could restric <script type="math/tex">x</script> into any Gaussian distribution, thus fixing the instability of <script type="math/tex">x</script> and <script type="math/tex">\sigma'</script>.</p>
<h3 id="perhaps-not-alleviate-internal-covariate-shift-1"><strong>(Perhaps not) Alleviate Internal Covariate Shift</strong> [1]</h3>
<p>In the original paper of Batch Normalizaion, they defined ICS.</p>
<blockquote>
<p>ICS is the phenomenon where the distribution of inputs to a layer in the network changes due to an update of parameters of the previous layers.</p>
</blockquote>
<p>Mathematically, each layer can be derived as:  <script type="math/tex; mode=display">Y = \mathcal{F}\{X\}</script>
Where <script type="math/tex">\mathcal{F}</script> is the mapping function between input <script type="math/tex">X</script> and output <script type="math/tex">Y</script>. Basically, they are learning this map between input pattern and output pattern. However, due to ICS, the input pattern could be constantly changing, and such changes could break the learnt mapping function; therefore, ICS is believed to have detrimental effect on training process.</p>
<p>I, however, would like to propose another understanding on ICS. In the traditional Machine learning, we assume that datas are <strong>IID</strong> (ie. independently and identically distributed).This is the foundation of Machine Learning, and the prerequisite of <strong>MLE</strong> (ie. Maximum Likelihood Estimation), which is the original form of all Loss functions. By exploiting BN, we surely guarantee the second <strong>I</strong> in <strong>IID</strong>, which is identically distributed. This could bring better generalizaiton performances to the network.</p>
<p><em>However, other researchers had shown that ICS will not effect performance and BN does not reduce ICS.</em> They prefer to explain the effectiveness of BN in another way.</p>
<h3 id="smoother-loss-landscape-2"><strong>Smoother Loss landscape</strong> [2]</h3>
<p>These researchers shown that BN contributes to the smoother Loss landscape, which could be visualized:
<img alt="" src="../Landscape.png" /></p>
<p>With BN, the Loss landscape is smoother, training efficiency will be improved, and that is why higher learning rate could be utilized. </p>
<h3 id="better-use-of-non-linearity-3"><strong>Better use of non-linearity</strong> [3]</h3>
<p>Please be noted, there is a linear transformation (ie. scale and shift) after feature map <script type="math/tex">x</script> is normalized.</p>
<p><img alt="" src="../BN.png" style="height:300px;" /></p>
<p>Let us suppose we use sigmoid function as activation function.</p>
<p><img alt="" src="../sigmoid-function.png" style="height:300px;" /></p>
<p>It is pretty clear that for <script type="math/tex">x\in (-1, 1)</script>, we have <script type="math/tex">\sigma(x)\approx x</script> . Which means the activation function is similar to an identity transformation. That is not a good sign, because the purpose of activation function is to add non-linearity in to the model. Therefore, without scale and shift, the non-linearity will be weak and the fitting process would be hard.</p>
<p>Even for ReLU, which seems not going to be heavily effected, also witnessed the situation where all the neurons are either activated <script type="math/tex">x>0</script> or deactivated <script type="math/tex">x<0</script>. Be aware that if a ReLU neuron is always active, then it is linear; if it is always deactive, then it does not exist.</p>
<p>But in my perspective, this might not be the most important contribution of BN. Experiments have proved that if we put BN after activation, network could even sometimes outperform!</p>
<h2 id="possible-advantages-of-skip-connection"><strong>Possible advantages of Skip-connection</strong></h2>
<h3 id="smoother-gradient-flow"><strong>Smoother gradient flow</strong></h3>
<p>This is pointed out in [4], which is written by the Resnet author He, that one benifit of Skip-connection is smoother gradient flow. For each skip-layer, the output can be derived as <script type="math/tex; mode=display">\mathbf{x}_{l+1}=\mathbf{x}_l+\mathcal{F}\left(\mathbf{x}_l, \mathcal{W}_l\right)</script> And the gradient is <script type="math/tex; mode=display">\frac{\partial \mathcal{E}}{\partial \mathbf{x}_l}=\frac{\partial \mathcal{E}}{\partial \mathbf{x}_L} \frac{\partial \mathbf{x}_L}{\partial \mathbf{x}_l}=\frac{\partial \mathcal{E}}{\partial \mathbf{x}_L}\left(1+\frac{\partial}{\partial \mathbf{x}_l} \sum_{i=l}^{L-1} \mathcal{F}\left(\mathbf{x}_i, \mathcal{W}_i\right)\right)</script>
Therefore, with resnet, gridient will be a sum of "geometric equation", and it will never vanish.</p>
<h3 id="solving-network-degradation-problem"><strong>Solving network degradation problem</strong></h3>
<p>In the original paper of Resnet, He claimed that resnet solved "network degradation problem". The original insight was: <em>if a deeper model perform worse than shallower model on test-set, it means that the extra layers of the deeper model failed to achieve identity mapping.</em> Because if the extra layers are identity mapping, then the deeper model are the same with the shallower model.</p>
<p>With this insight, he designed this skip-connection, which is basicly a manually added identity mapping.</p>
<p>Now the real problem is, what caused such network degradation? Is the degradation problem really because of the failure of achieving indentity mapping? That is where researchers would argue, and I would present some of the interesting researches here.</p>
<p><strong>Gradient correlation [2]</strong><br />
Balduzzi et al. [2] proposed a new explaination for network degradation. They first claimed that ResNet actually allievated the shattered gradient problem. The shattered gradient problem has such definations:</p>
<blockquote>
<p>Shattered gradients undermine the effectiveness of algorithms that assume gradients at nearby points are similar such as momentum-based and accelerated methods.</p>
</blockquote>
<p>Under this assumption, they quantilized the shattered gradient problem as the autocorrelation function (ACF). A higher ACF leads to higher performance and less shattered correlation problem. They proceeded to demonstrate, both through mathematical proofs and experiments, that skip connections have the capability to enhance ACF. However, their mathematical proof was under very strong assumption, and was not so persuasive to me.</p>
<p><img alt="ACF" src="../ACF.png" title="title" /></p>
<h2 id="citation">Citation</h2>
<p>[1] Batch normalization: Accelerating deep network training by reducing internal covariate shift.<br />
[2] How Does Batch Normalization Help Optimization?<br />
[3] The shattered gradients problem: If resnets are the answer, then what is the question?<br />
[4] Identity mappings in deep residual networks.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.a7c05c9e.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>